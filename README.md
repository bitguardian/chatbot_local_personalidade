
# ğŸ¤– Chatbot Local com Personalidade

Um chatbot inteligente, 100% **offline**, alimentado por modelos de linguagem locais como **Zephyr**, **Mistral**, **LLaMA 2** e outros via [Ollama](https://ollama.com/). O projeto foi desenvolvido em **Python 3.10** e oferece memÃ³ria persistente, estilos de resposta personalizÃ¡veis e interface moderna com **Gradio**.

---

## ğŸ“š Como funciona?

Este chatbot utiliza modelos LLM rodando localmente via Ollama, sem necessidade de conexÃ£o com a nuvem. A aplicaÃ§Ã£o mantÃ©m um histÃ³rico das conversas (memÃ³ria), permitindo respostas contextualizadas e personalizadas conforme o estilo escolhido pelo usuÃ¡rio:

- **AmigÃ¡vel**: Respostas acolhedoras e descontraÃ­das.
- **Formal**: Respostas educadas e profissionais.
- **SarcÃ¡stico**: Respostas irÃ´nicas e bem-humoradas.

O usuÃ¡rio interage via uma interface web (Gradio), seleciona o estilo desejado e conversa normalmente. Todo o histÃ³rico Ã© salvo localmente, garantindo privacidade e funcionamento offline.

---

## ğŸ—‚ï¸ Estrutura do Projeto

```
chatbot_local_personalidade/
â”œâ”€â”€ chatbot.py                 # FunÃ§Ãµes de memÃ³ria, montagem de prompt e personalidades
â”œâ”€â”€ main.py                    # Interface Gradio e integraÃ§Ã£o com Ollama
â”œâ”€â”€ requirements.txt           # DependÃªncias do projeto
â”œâ”€â”€ README.md                  # Este arquivo
â”œâ”€â”€ memory/
â”‚   â””â”€â”€ session_log.json       # HistÃ³rico persistente das conversas
â”œâ”€â”€ personality_prompts/
â”‚   â”œâ”€â”€ friendly.txt           # Prompt para personalidade amigÃ¡vel
â”‚   â”œâ”€â”€ formal.txt             # Prompt para personalidade formal
â”‚   â””â”€â”€ sarcastic.txt          # Prompt para personalidade sarcÃ¡stica
```

---

## ğŸ§  Funcionalidades

- **LLM local** via Ollama (Zephyr, Mistral, LLaMA 2, etc)
- **Rodando 100% offline** (sem nuvem)
- **MemÃ³ria persistente**: histÃ³rico salvo em `memory/session_log.json`
- **Personalidades customizÃ¡veis**: escolha entre amigÃ¡vel, formal ou sarcÃ¡stico
- **Interface moderna**: chat web com Gradio
- **FÃ¡cil expansÃ£o**: adicione novos estilos criando arquivos em `personality_prompts/`

---

## ğŸ› ï¸ Requisitos

- **Python 3.10** (recomendado)
- [Ollama instalado e funcionando](https://ollama.com)
- Modelo LLM jÃ¡ baixado (ex: `ollama run zephyr`)
- Bibliotecas Python (veja `requirements.txt`)

---

## ğŸš€ Como rodar o projeto

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/bitguardian/chatbot_local_personalidade.git
cd chatbot-local-personalidade

# 2. Instale as dependÃªncias
pip install -r requirements.txt

# 3. Inicie o modelo local (Zephyr, Mistral, etc)
ollama run zephyr

# 4. Execute o chatbot
python main.py
```

---

## ğŸ’¡ Personalidades

Os estilos de resposta sÃ£o definidos por arquivos em `personality_prompts/`. Para criar novos estilos, basta adicionar um novo arquivo `.txt` com instruÃ§Ãµes para o modelo.

---

## ğŸ“ MemÃ³ria de Conversa

O histÃ³rico das conversas Ã© salvo em `memory/session_log.json`, permitindo que o chatbot lembre interaÃ§Ãµes anteriores e responda de forma mais contextualizada.

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob os termos da [LicenÃ§a MIT](LICENSE).
